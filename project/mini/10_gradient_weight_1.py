from tensorflow.keras.datasets import mnist

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation
from tensorflow.keras.layers import MaxPooling2D, Add, GlobalAveragePooling2D, Dense

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

x_train.resize(x_train.shape[0], 256, 256, 1)
x_test.resize(x_test.shape[0], 256, 256, 1)

x_train = x_train[:500]
x_test = x_test[:100]

y_train = to_categorical(y_train)[:500]
y_test = to_categorical(y_test)[:100]

print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

input_tensor = Input(shape=x_train.shape[1:], dtype='float32', name='input')

def conv1_layer(x):    
    x = ZeroPadding2D(padding=(3, 3))(x)
    x = Conv2D(64, (7, 7), strides=(2, 2))(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = ZeroPadding2D(padding=(1,1))(x)
 
    return x   

def conv2_layer(x):         
    x = MaxPooling2D((3, 3), 2)(x)     
 
    shortcut = x
 
    for i in range(3):
        if (i == 0):
            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)
            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            
            x = BatchNormalization()(x)
            shortcut = BatchNormalization()(shortcut)
 
            x = Add()([x, shortcut])
            x = Activation('relu')(x)
            
            shortcut = x
 
        else:
            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)            
 
            x = Add()([x, shortcut])   
            x = Activation('relu')(x)  
 
            shortcut = x        
    
    return x

def conv3_layer(x):        
    shortcut = x    
    
    for i in range(4):     
        if(i == 0):            
            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)
            x = BatchNormalization()(x)
            shortcut = BatchNormalization()(shortcut)            
 
            x = Add()([x, shortcut])    
            x = Activation('relu')(x)    
 
            shortcut = x              
        
        else:
            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)            
 
            x = Add()([x, shortcut])     
            x = Activation('relu')(x)
 
            shortcut = x      
            
    return x
 
def conv4_layer(x):
    shortcut = x        
  
    for i in range(6):     
        if(i == 0):            
            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)
            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)
            x = BatchNormalization()(x)
            shortcut = BatchNormalization()(shortcut)
 
            x = Add()([x, shortcut]) 
            x = Activation('relu')(x)
 
            shortcut = x               
        
        else:
            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)            
 
            x = Add()([x, shortcut])    
            x = Activation('relu')(x)
 
            shortcut = x      
 
    return x
 
def conv5_layer(x):
    shortcut = x    
  
    for i in range(3):     
        if(i == 0):            
            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)
            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)
            x = BatchNormalization()(x)
            shortcut = BatchNormalization()(shortcut)            
 
            x = Add()([x, shortcut])  
            x = Activation('relu')(x)      
 
            shortcut = x               
        
        else:
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)
            x = BatchNormalization()(x)           
            
            x = Add()([x, shortcut]) 
            x = Activation('relu')(x)       
 
            shortcut = x                  
 
    return x
 
x = conv1_layer(input_tensor)
x = conv2_layer(x)
x = conv3_layer(x)
x = conv4_layer(x)
x = conv5_layer(x)
 
x = GlobalAveragePooling2D()(x)
output_tensor = Dense(10, activation='softmax')(x)

model = Model(input_tensor, output_tensor)

model.summary()

print(model.get_weights())
'''
[array([[[[-0.02802281,  0.00302224, -0.03750984, ..., -0.03500971,
          -0.02867907, -0.03808827]],

        [[-0.04024483, -0.02630195,  0.02454561, ..., -0.04194941,
          -0.03936101,  0.00079736]],

        [[-0.03603058,  0.01433139,  0.02180958, ..., -0.02238224,
           0.0069213 ,  0.01599707]],
'''

model.compile(loss='categorical_crossentropy', optimizer='adam')
model.fit(x_train, y_train, epochs=100, batch_size=32)
print(model.trainable_weights)

'''
array([[[[-0.00861823, -0.04007689,  0.04124244, ...,  0.03586021,
           0.0188487 ,  0.01574213]],

        [[ 0.03081935,  0.0008652 ,  0.01869856, ..., -0.0230858 ,
          -0.02055189, -0.019556  ]],

        [[ 0.00655324,  0.0117908 ,  0.01047264, ..., -0.01499968,
           0.00440163, -0.02889732]],

        ...,

        [[ 0.01703496,  0.00243678,  0.03803981, ..., -0.01331334,
          -0.00233869, -0.02169248]],

        [[ 0.00248106,  0.0323399 , -0.03537916, ...,  0.0105953 ,
          -0.03863707,  0.04295584]],

        [[-0.02108146,  0.02222609, -0.00864004, ..., -0.04077119,
          -0.03133301, -0.00864698]]],


       [[[ 0.02522822,  0.01707321,  0.02285453, ...,  0.01766359,
          -0.01568225, -0.01519994]],

        [[ 0.01869788,  0.02434516, -0.01226495, ...,  0.03184432,
           0.03354512,  0.03742314]],

        [[ 0.0103389 , -0.00269629, -0.01079424, ..., -0.00798214,
          -0.00367502, -0.03601576]],

        ...,

        [[-0.02979025,  0.03937884,  0.0188753 , ..., -0.02735911,
          -0.04106564,  0.0176022 ]],

        [[-0.00350307, -0.01231076,  0.00227617, ..., -0.02797265,
          -0.0123438 ,  0.01695151]],

        [[-0.02496145, -0.04597549, -0.03992173, ...,  0.01084435,
          -0.05088908, -0.02442792]]],


       [[[-0.01550816, -0.00319179, -0.03711315, ..., -0.00702943,
          -0.01402232,  0.02454112]],

        [[ 0.03645435,  0.00086026, -0.00138466, ..., -0.00120341,
           0.00465425,  0.04737457]],

        [[-0.00483878,  0.0085917 ,  0.01413038, ...,  0.02595981,
          -0.0318963 ,  0.03185679]],

        ...,

        [[-0.02368369, -0.02497569, -0.00978159, ..., -0.03032053,
           0.02784794,  0.03563476]],

        [[-0.02490914, -0.00347756, -0.00978506, ..., -0.00210288,
          -0.03337814, -0.03280971]],

        [[ 0.03326064,  0.02739938, -0.0205621 , ..., -0.0184585 ,
           0.05095229, -0.02719089]]],


       ...,


       [[[ 0.01319981, -0.03092845, -0.04519499, ...,  0.04428441,
          -0.0319091 ,  0.04813782]],

        [[-0.00088688,  0.042523  , -0.01976014, ...,  0.04456066,
          -0.05368259, -0.02423449]],

        [[-0.04922633, -0.02639318, -0.03835877, ...,  0.01367893,
           0.02614239,  0.04344084]],

        ...,

        [[ 0.02975282,  0.00461438, -0.04780577, ..., -0.01613245,
           0.00906122, -0.02603932]],

        [[ 0.01973025,  0.01843067, -0.04444901, ...,  0.00604476,
           0.01589595, -0.01216671]],

        [[ 0.01754415, -0.02290577,  0.02207983, ...,  0.01960663,
           0.02880881, -0.02228996]]],


       [[[ 0.04312852, -0.00789573,  0.02858899, ...,  0.01578159,
          -0.02712337, -0.02979892]],

        [[-0.02440892, -0.00992611,  0.02526483, ...,  0.05126639,
           0.03946124,  0.0419876 ]],

        [[ 0.04070319, -0.00026568, -0.0282532 , ..., -0.0192484 ,
          -0.02108047, -0.00620614]],

        ...,

        [[-0.02373301,  0.01374099,  0.02726293, ..., -0.03200454,
          -0.06575014,  0.01322692]],

        [[ 0.03030064, -0.00481609, -0.02316996, ...,  0.05402943,
          -0.00309159,  0.0067536 ]],

        [[-0.04282528, -0.01554505, -0.01629819, ...,  0.03378433,
           0.03352292,  0.01904222]]],


       [[[-0.02180586, -0.02427386, -0.00812757, ..., -0.03968933,
           0.03011788,  0.02225474]],

        [[-0.02377588,  0.00765126,  0.02025027, ...,  0.00175753,
           0.01048025,  0.0153531 ]],

        [[-0.05047543, -0.01657962, -0.02699695, ..., -0.01259692,
           0.03872633, -0.04865446]],

        ...,

        [[ 0.01204525, -0.04638566, -0.00985785, ..., -0.00868961,
          -0.01564896,  0.03278894]],

        [[-0.04697995,  0.03775025,  0.05071265, ...,  0.01267455,
           0.01095441,  0.02308621]],

        [[ 0.00603065,  0.00191128,  0.01069203, ..., -0.00624781,
           0.02593029,  0.0355202 ]]]], dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32, numpy=
array([ 8.7138258e-05,  6.9177721e-04, -3.1300036e-03, -7.6688448e-04,
        7.4103836e-04, -9.0810406e-04, -1.7626482e-03,  7.2744573e-05,
       -1.4069229e-03,  5.1919336e-04, -1.2006853e-05,  1.4338973e-03,
        4.9412769e-04,  1.1731434e-03,  3.7306602e-04, -7.6510618e-04,
        1.1653597e-03,  1.0768728e-03,  4.6523681e-05,  6.4216333e-04,
       -2.0054328e-04,  1.3905020e-04,  4.9509306e-04,  1.2652202e-04,
       -2.0422773e-03,  2.3792991e-03,  1.4558551e-03,  1.2878474e-03,
        2.4907017e-04, -1.1257316e-03,  6.1615818e-04, -1.6310494e-03,
       -6.1019085e-04,  3.4712924e-04, -1.3201749e-03,  1.5119341e-03,
       -6.4117392e-04,  1.1101195e-03, -2.4799434e-03,  1.2972789e-03,
        8.0177392e-04, -2.1651366e-03, -1.6340732e-03,  6.9361384e-05,
        1.0742421e-03, -2.4670135e-04, -2.3886357e-03,  1.4701880e-03,
        2.3742872e-03,  7.5731211e-04,  7.3747156e-04, -3.1655977e-04,
        8.6828752e-04,  2.7754835e-03, -6.3291407e-04, -4.5266579e-06,
       -2.1387832e-03, -4.6885791e-04,  3.6152353e-05, -1.2826968e-04,
       -2.0115841e-03,  1.1531222e-03,  7.4352778e-04,  1.9851970e-03],
      dtype=float32)>, <tf.Variable 'batch_normalization/gamma:0' shape=(64,) dtype=float32, numpy=
array([0.9937803 , 1.0217578 , 1.0044065 , 0.9846393 , 0.99335843,
       0.9984228 , 0.99753046, 0.99578416, 0.9900896 , 1.0041108 ,
       1.0049943 , 0.98006445, 1.0177493 , 0.99022436, 1.0127226 ,
       1.0136013 , 0.9841225 , 1.0113543 , 0.98950034, 0.9870627 ,
       1.0006884 , 1.0089753 , 0.99401873, 0.9992233 , 1.0090638 ,
       1.0034045 , 1.0058962 , 0.98579067, 1.0097333 , 0.98879755,
       1.0010273 , 0.99472827, 1.0102254 , 1.0014405 , 0.9986616 ,
       1.0078589 , 0.98165137, 0.9937911 , 1.003455  , 1.0062184 ,
       0.9822555 , 0.9941432 , 1.0037817 , 0.98975366, 1.0090543 ,
       1.0043223 , 1.0025301 , 1.022361  , 1.011653  , 1.01586   ,
       0.99850225, 1.007718  , 0.9980852 , 0.9794179 , 0.9850468 ,
       0.9992608 , 1.0142552 , 0.98891383, 1.0184374 , 0.9973174 ,
       0.99219954, 1.0100771 , 0.9984985 , 1.0006334 ], dtype=float32)>, <tf.Variable 'batch_normalization/beta:0' shape=(64,) dtype=float32, numpy=
array([-0.01745599,  0.01691882,  0.00539909, -0.00775814,  0.00307287,
       -0.01096107, -0.00091967,  0.00407078,  0.00437525,  0.02217628,
       -0.00266055, -0.02243694,  0.00359282,  0.01620119, -0.02140721,
        0.0003288 , -0.00936664, -0.00734003,  0.0188446 , -0.00787765,
        0.0076663 , -0.0094651 ,  0.0214454 , -0.00228575,  0.0070147 ,
        0.01654408,  0.01655274,  0.01250715,  0.00411407, -0.00427405,
        0.0112253 ,  0.00314027,  0.00665487, -0.0005184 , -0.00764868,
        0.018199  , -0.00540918, -0.00048817,  0.0036224 , -0.00366488,
       -0.02088556, -0.00384692, -0.01541843, -0.02074259,  0.00613536,
       -0.00918993,  0.020429  , -0.00588838,  0.0290064 ,  0.00096191,
        0.00827495,  0.00923374, -0.0153463 ,  0.0085541 ,  0.01146486,
       -0.01229736,  0.0034828 , -0.00099676,  0.01791403,  0.00119   ,
       -0.00224346, -0.00329435, -0.00301752, -0.00049088], dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(1, 1, 64, 64) dtype=float32, numpy=
array([[[[ 0.08822498, -0.09686679, -0.14491986, ..., -0.1110762 ,
           0.16460769, -0.11202728],
         [-0.19152471,  0.00793442, -0.09556729, ...,  0.13729791,
          -0.07305135, -0.08890591],
         [ 0.1840887 ,  0.10408591,  0.06190993, ...,  0.16716506,
          -0.17525691,  0.20043166],
         ...,
         [-0.0322823 ,  0.09197822,  0.09953199, ..., -0.13425657,
           0.04880061, -0.0845569 ],
         [ 0.08141027,  0.19897206,  0.19257475, ...,  0.0298076 ,
          -0.0112868 , -0.20915471],
         [ 0.0118991 ,  0.06211483,  0.10845903, ...,  0.04712301,
          -0.14912656,  0.02731358]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=
array([ 0.01192418,  0.00624006, -0.00224215,  0.00351528, -0.00083792,
       -0.0005746 ,  0.01000176,  0.0072952 ,  0.00305758, -0.00034407,
        0.00777967, -0.00805433, -0.01099549, -0.00222717,  0.0069991 ,
       -0.00404261,  0.00207758, -0.00597217, -0.00520553,  0.00631171,
        0.00888034,  0.00563269,  0.00413399, -0.00909543,  0.00080899,
       -0.0050419 ,  0.00412244,  0.00290172, -0.0025006 ,  0.00577442,
       -0.00683654, -0.00441996, -0.01240802, -0.00238109,  0.00116551,
       -0.00922381, -0.00564929, -0.0063968 ,  0.00498892,  0.00442386,
        0.00381364, -0.00693981,  0.00370837, -0.00713396,  0.01250163,
       -0.00497145, -0.00231165, -0.00031376,  0.00493377,  0.00129273,
        0.00327519,  0.0109136 ,  0.0003949 , -0.01491946, -0.00019801,
       -0.00233534, -0.0008064 , -0.0033266 ,  0.00017651,  0.00885776,
       -0.00817562, -0.00092175, -0.01623613,  0.00094056], dtype=float32)>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(64,) dtype=float32, numpy=       
array([1.0007223 , 1.0197564 , 0.99374485, 1.0191917 , 1.0066295 ,
       0.98018956, 1.0041063 , 0.9933926 , 0.9917955 , 0.9856383 ,
       1.0215315 , 0.9959103 , 0.9880594 , 1.0078962 , 0.9895508 ,
       1.0006512 , 0.99277145, 1.0026765 , 1.0039    , 1.0086328 ,
       0.9940106 , 1.0022668 , 1.000969  , 0.9874808 , 1.0073315 ,
       0.99138486, 0.9944279 , 1.0085218 , 1.0186621 , 0.9883792 ,
       0.9907752 , 1.0081217 , 0.9892211 , 0.9970823 , 1.0038787 ,
       0.99167246, 1.0237398 , 0.99551225, 1.0031697 , 0.9834284 ,
       1.0206186 , 0.9877919 , 0.9839758 , 0.9829722 , 1.000489  ,
       0.98855996, 1.0149732 , 0.99634194, 1.002579  , 1.0047257 ,
       1.0143485 , 0.9887001 , 0.9932307 , 1.0156626 , 0.99166435,
       1.0085849 , 0.99749416, 1.0010083 , 1.0100765 , 0.9953217 ,
       0.9995487 , 1.0045416 , 1.0112987 , 0.99878407], dtype=float32)>, <tf.Variable 'batch_normalization_1/beta:0' shape=(64,) dtype=float32, numpy=
array([-0.00796337,  0.00058041,  0.01741538,  0.00791866, -0.00944787,
       -0.02249199, -0.00272683,  0.00999589, -0.00397833, -0.02294377,
        0.02819292,  0.00612131, -0.00437935,  0.01123956,  0.00135743,
       -0.00604102, -0.00637204,  0.00357212,  0.0008769 ,  0.00877044,
       -0.00533111, -0.0050047 , -0.00934467, -0.02286711,  0.00549669,
        0.008996  ,  0.00318758, -0.00285284,  0.01394032, -0.03133338,
       -0.00591774,  0.01931977,  0.00011747, -0.00315767,  0.00112123,
       -0.00570436,  0.02038405,  0.00333886, -0.00478846, -0.02497516,
       -0.00097136, -0.00715449, -0.02643388, -0.03073797,  0.00157639,
       -0.00708983,  0.01141295,  0.00322167, -0.00577621,  0.00468438,
        0.01075915, -0.00220824, -0.00066855,  0.00312092,  0.00143349,
       -0.00065914, -0.0109999 ,  0.00018892,  0.00763912, -0.00220617,
       -0.00601056,  0.00872017,  0.01944979,  0.00168217], dtype=float32)>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=
array([[[[-0.04163146,  0.01413911,  0.01271517, ..., -0.01308732,
          -0.03745451
'''