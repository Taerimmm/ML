from tensorflow.keras.datasets import mnist

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation
from tensorflow.keras.layers import MaxPooling2D, Add, GlobalAveragePooling2D, Dense

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

x_train.resize(x_train.shape[0], 256, 256, 1)
x_test.resize(x_test.shape[0], 256, 256, 1)

x_train = x_train[:500]
x_test = x_test[:100]

y_train = to_categorical(y_train)[:500]
y_test = to_categorical(y_test)[:100]

print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

input_tensor = Input(shape=x_train.shape[1:], dtype='float32', name='input')

def conv1_layer(x):    
    x = ZeroPadding2D(padding=(3, 3))(x)
    x = Conv2D(64, (7, 7), strides=(2, 2))(x)
    # x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = ZeroPadding2D(padding=(1,1))(x)
 
    return x   

def conv2_layer(x):         
    x = MaxPooling2D((3, 3), 2)(x)     
 
    for i in range(3):
        x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)
        # x = BatchNormalization()(x)
        x = Activation('relu')(x)
        
        x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)
        # x = BatchNormalization()(x)
        x = Activation('relu')(x)

        x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)     
        # x = BatchNormalization()(x)
        x = Activation('relu')(x)
    
    return x

def conv3_layer(x):            
    for i in range(4):     
        if(i == 0):            
            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)          
        
        else:
            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)            
            x = Activation('relu')(x)
            
    return x
 
def conv4_layer(x):
    for i in range(6):     
        if(i == 0):            
            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
        
        else:
            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)            
            x = Activation('relu')(x)
 
    return x
 
def conv5_layer(x):  
    for i in range(3):     
        if(i == 0):            
            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)        
            
            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)  
 
            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)      
        else:
            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
            
            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)
            # x = BatchNormalization()(x)
            x = Activation('relu')(x)
 
            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)
            # x = BatchNormalization()(x)           
            x = Activation('relu')(x)       
 
    return x
 
x = conv1_layer(input_tensor)
x = conv2_layer(x)
x = conv3_layer(x)
x = conv4_layer(x)
x = conv5_layer(x)
 
x = GlobalAveragePooling2D()(x)
output_tensor = Dense(10, activation='softmax')(x)

model = Model(input_tensor, output_tensor)

model.summary()

print(model.get_weights())
'''
[array([[[[ 0.0248051 ,  0.00946642, -0.01248691, ..., -0.01372005,
          -0.02683471, -0.00981986]],

        [[ 0.01475429, -0.01016986,  0.03634847, ..., -0.02175853,
           0.02192241, -0.00272936]],

        [[-0.01862933, -0.03592018, -0.00456616, ..., -0.0322857 ,
          -0.00406815, -0.04105092]],
'''

model.compile(loss='categorical_crossentropy', optimizer='adam')
model.fit(x_train, y_train, epochs=100, batch_size=32)
print(model.trainable_weights)

'''
array([[[[ 0.01014808, -0.01719562, -0.03494288, ..., -0.02812066,
          -0.02872761, -0.04287659]],

        [[ 0.006868  ,  0.02747155, -0.03362967, ...,  0.02659578,
           0.02157061,  0.03192711]],

        [[-0.02455361, -0.03971748, -0.01261091, ..., -0.03079004,
           0.04264648, -0.02669932]],

        ...,

        [[-0.01840179,  0.01937498, -0.0388312 , ..., -0.01760127,
          -0.03251716, -0.04087606]],

        [[-0.01917464, -0.00337895, -0.00829314, ...,  0.00450494,
          -0.02672983, -0.03931814]],

        [[-0.03626294,  0.02047062,  0.00591765, ...,  0.00906308,
          -0.01826469,  0.03973778]]],


       [[[ 0.00307307, -0.03373246,  0.02103776, ..., -0.03256007,
           0.02749863, -0.00773117]],

        [[ 0.03842597, -0.00430685, -0.0044717 , ...,  0.01681145,
          -0.03272339, -0.00201907]],

        [[-0.01141043,  0.04105923, -0.01798486, ...,  0.0398103 ,
          -0.0226051 ,  0.0005649 ]],

        ...,

        [[ 0.02293637, -0.0365212 , -0.002142  , ...,  0.03330417,
          -0.03669874,  0.02856734]],

        [[ 0.02050715,  0.01316578, -0.02632151, ...,  0.0292284 ,
          -0.00429608, -0.01494352]],

        [[-0.00652422,  0.02589823, -0.04080105, ..., -0.03614926,
           0.00938277, -0.02663457]]],


       [[[-0.03900526, -0.00180792,  0.03609156, ...,  0.0005207 ,
           0.02761819,  0.00767397]],

        [[ 0.02065837,  0.03461729,  0.01109969, ...,  0.01496425,
          -0.04042855,  0.02865967]],

        [[ 0.02051673,  0.042537  , -0.03745328, ..., -0.03991392,
           0.02514468,  0.00595279]],

        ...,

        [[ 0.02642463,  0.0262463 , -0.0062874 , ..., -0.00992686,
          -0.02457869, -0.00302421]],

        [[-0.02998512, -0.00459579,  0.00544788, ..., -0.01340501,
          -0.01408493,  0.01242919]],

        [[ 0.01778996, -0.02433212, -0.03377194, ...,  0.02201675,
           0.0346913 , -0.0364623 ]]],


       ...,


       [[[ 0.00511215,  0.03308468, -0.00830405, ..., -0.0138275 ,
           0.04194165,  0.0074476 ]],

        [[-0.00269486, -0.03283944,  0.02965192, ..., -0.01765831,
           0.03591673, -0.00951966]],

        [[ 0.01688209, -0.02663771, -0.0382454 , ..., -0.01942431,
           0.03760562, -0.01681628]],

        ...,

        [[-0.01012786, -0.03329184,  0.03182783, ..., -0.02365112,
          -0.03582641, -0.02944364]],

        [[-0.02516455, -0.03915744, -0.01722625, ..., -0.01546406,
          -0.02716111,  0.04330992]],

        [[-0.00370743,  0.01086506,  0.03012924, ...,  0.01476623,
          -0.02660615, -0.01576817]]],


       [[[ 0.03932773, -0.01064181, -0.02016059, ...,  0.03606797,
          -0.009036  ,  0.04179379]],

        [[ 0.03425329, -0.04231768, -0.00109398, ...,  0.01585319,
           0.03967085, -0.04161657]],

        [[-0.00163634, -0.03735479, -0.01257491, ...,  0.01242332,
          -0.01009871, -0.01927204]],

        ...,

        [[-0.0282384 ,  0.00835425,  0.00995395, ..., -0.00022972,
           0.00730361, -0.01931006]],

        [[-0.03754354,  0.00385736, -0.02999287, ..., -0.01960168,
          -0.03506818,  0.01582548]],

        [[-0.04308876, -0.03282255, -0.00420959, ..., -0.00015631,
           0.03077802, -0.03916613]]],


       [[[ 0.02374933, -0.024949  ,  0.0158745 , ...,  0.00204298,
           0.03050232, -0.0307826 ]],

        [[ 0.0402569 , -0.03057807,  0.00230634, ...,  0.02901681,
          -0.01577794, -0.03139568]],

        [[-0.01390764, -0.00855153, -0.02694583, ...,  0.00490451,
          -0.00746623, -0.01225307]],

        ...,

        [[ 0.03587258, -0.03365473,  0.03857392, ..., -0.03867238,
          -0.02183614, -0.03685929]],

        [[-0.0308484 , -0.032589  , -0.03439597, ..., -0.00937196,
          -0.02880321,  0.024844  ]],

        [[-0.03894352, -0.02014429, -0.04223932, ..., -0.03344791,
          -0.03068221, -0.00167956]]]], dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32, numpy=
array([-8.63034515e-08, -1.33934615e-08, -3.33110748e-08, -1.02946991e-07,
        2.26675709e-08,  1.58062474e-09,  2.04073363e-08,  6.40810356e-08,
        5.27697743e-08, -5.26953450e-08,  5.16349985e-08, -8.94246721e-09,
       -1.06889271e-08, -2.70705431e-08, -1.91734646e-08, -4.22440358e-08,
       -1.72278760e-08, -9.87162210e-08, -3.99323490e-08,  8.58419043e-08,
       -6.50299299e-08, -2.58107864e-08,  5.31789546e-08, -6.36827195e-08,
        1.96258672e-08, -1.06921377e-07,  7.53482965e-08, -1.24181136e-08,
       -1.49864743e-09,  4.35879670e-08,  7.95696486e-09,  5.17272909e-08,
        7.19869497e-09,  1.36281852e-09, -6.02504358e-08,  3.86380457e-08,
       -9.98057459e-08, -1.95249434e-08, -6.88183093e-08,  1.09914708e-08,
        7.92701158e-08,  2.44411531e-08,  1.58558624e-08, -1.68754841e-08,
       -1.00078125e-07, -5.95094818e-08,  4.59915022e-08, -5.10337266e-08,
       -6.84930228e-08,  2.62083706e-08, -1.85053111e-08, -2.53826808e-08,
       -9.60307602e-08, -5.04031306e-08, -7.24972793e-08,  5.86266147e-08,
        5.03564941e-08, -3.94505939e-09,  1.73031989e-08, -7.29261984e-08,
       -5.33867883e-08, -6.89145736e-08,  9.41631200e-08, -4.52151205e-08],
      dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(1, 1, 64, 64) dtype=float32, numpy=
array([[[[-0.16674933,  0.14120989, -0.08774376, ..., -0.13502268,
           0.08671897, -0.10098102],
         [-0.17904827, -0.14842504,  0.18838616, ...,  0.04455972,
          -0.20035073, -0.14139575],
         [ 0.11441435, -0.10743261,  0.05681952, ..., -0.07943177,
           0.01768784,  0.02378084],
         ...,
         [ 0.07502733,  0.09854454, -0.20332658, ..., -0.17315878,
          -0.01061825, -0.20156012],
         [-0.01204006,  0.03182935, -0.14587072, ..., -0.18707106,
          -0.09040212, -0.17567933],
         [ 0.08537463, -0.11229258,  0.04447955, ..., -0.15824232,
          -0.0419508 , -0.03356256]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=
array([ 9.39053102e-09, -2.98026137e-09,  1.34877731e-09, -1.21574445e-07,
       -6.52610481e-08, -9.23492749e-08,  1.75084947e-09, -9.84919950e-08,
       -1.61375871e-10,  6.17428730e-09, -4.95810476e-11,  2.96804128e-08,
       -8.28192537e-09,  1.30521878e-08, -4.48080826e-08,  0.00000000e+00,
        3.73499773e-08,  4.24287485e-08,  1.57261593e-09, -4.33314540e-09,
        1.46083721e-07,  6.56181331e-09,  3.71119935e-09,  1.80451053e-07,
        4.91141261e-09, -1.57054526e-11,  4.99782749e-09, -7.03195058e-10,
       -6.87801531e-08, -6.75966376e-08, -3.07123260e-09,  1.08608006e-07,
       -1.18179404e-08,  7.87209853e-09,  8.37917256e-08,  2.31614306e-09,
       -2.10660767e-10,  6.16335782e-08, -1.11313888e-07,  1.69807208e-08,
        7.65926211e-11, -2.56491379e-08, -6.17470022e-08,  1.04547884e-10,
       -8.19565855e-08, -6.34193498e-08,  1.70421401e-08,  5.05681541e-09,
       -5.38394551e-10, -1.15694538e-08, -4.15996542e-16, -6.12836781e-10,
       -1.13663861e-08, -1.34452875e-07, -2.28758390e-09, -3.88507837e-10,
       -1.81413062e-11, -2.08462438e-07, -1.45510839e-08,  4.02936209e-08,
       -1.40367634e-10,  1.76413870e-08, -1.82321216e-08,  8.48961124e-10],
      dtype=float32)>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=
array([[[[-6.93320185e-02,  3.81965786e-02,  5.20701520e-02, ...,
           6.26912862e-02,  6.82700127e-02,  1.19457692e-02],
         [ 5.62867373e-02, -4.84137423e-02, -7.98179768e-03, ...,
           6.17508143e-02,  1.05670765e-02, -5.29989675e-02],
         [-5.56856059e-02, -4.67951559e-02,  2.20316648e-03, ...,
          -1.38423778e-02, -4.08246107e-02,  6.13479316e-02],
         ...,
         [ 1.72477437e-03, -6.26379773e-02, -2.65477709e-02, ...,
           7.08844960e-02, -2.87812911e-02, -2.42882669e-02],
         [ 4.73311879e-02,  2.08069012e-02,  4.84705642e-02, ...,
           5.87280244e-02,  2.26042178e-02,  2.74268985e-02],
         [ 6.78550005e-02,  6.31684363e-02,  2.32361853e-02, ...,
          -3.95874567e-02,  6.25407100e-02, -5.93070649e-02]],

        [[-3.34740765e-02, -6.36770055e-02, -5.43952286e-02, ...,
           4.69790921e-02, -6.14309348e-02, -5.05657494e-03],
         [ 7.13602304e-02,  5.94472140e-03,  6.69094324e-02, ...,
           7.21211135e-02,  2.75344029e-02,  6.58159256e-02],
         [-4.10839990e-02, -4.59774919e-02, -5.09813894e-03, ...,
           6.00962490e-02, -1.04557499e-02, -7.07999468e-02],
         ...,
         [ 6.62289485e-02, -3.12828971e-03,  3.93296629e-02, ...,
          -7.12170586e-05,  5.54354526e-02, -4.67530489e-02],
         [-3.15520987e-02, -2.14706864e-02, -3.34354937e-02, ...,
          -5.40618747e-02,  4.99125123e-02, -1.43688899e-02],
         [-5.57439514e-02,  2.42517516e-02,  6.92327023e-02, ...,
          -1.78363733e-02, -7.00846910e-02,  5.66830039e-02]],

        [[ 2.69064624e-02, -3.89271602e-02, -3.15165147e-02, ...,
          -1.43430121e-02, -2.73186583e-02,  5.01106009e-02],
         [-5.60686924e-02, -6.66969121e-02, -5.28583229e-02, ...,
           4.51369733e-02, -2.34683119e-02,  4.88868505e-02],
         [ 5.25016263e-02, -2.76274905e-02, -4.45068814e-03, ...,
           4.69016805e-02,  5.36264777e-02, -6.47626072e-03],
         ...,
         [ 5.21272272e-02,  3.06888670e-02,  3.91092114e-02, ...,
          -5.36078811e-02,  4.06262875e-02,  6.49411678e-02],
         [-2.18207799e-02,  3.37487040e-03, -1.48246977e-02, ...,
           3.29203755e-02, -3.85910980e-02,  5.17549962e-02],
         [ 1.62287131e-02,  1.98057294e-03, -6.14745021e-02, ...,
           5.01520187e-02,  3.06050554e-02, -1.43993832e-02]]],


       [[[ 5.04670329e-02, -1.00478716e-02, -2.64208838e-02, ...,
           2.07383186e-03, -8.43354594e-03,  3.97496745e-02],
         [ 4.43782285e-02,  3.36843058e-02,  1.55138364e-02, ...,
           2.13123560e-02, -6.66498393e-02,  7.16475993e-02],
         [ 3.25737111e-02, -6.55944794e-02,  1.75538082e-02, ...,
          -1.29460432e-02,  1.16626397e-02,  3.02273929e-02],
         ...,
         [ 4.22822013e-02,  6.45158291e-02,  2.83569656e-02, ...,
          -5.34626050e-03,  2.39554867e-02, -1.64578704e-03],
         [-2.83156335e-02,  5.42793274e-02,  7.06309006e-02, ...,
          -5.69041781e-02,  5.4275696
'''