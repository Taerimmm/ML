
# 주제 : Mel Spectrogram 을 이용한 음원 분석 및 장르 구별, 추천 구현?

요즘 외국노래를 많이 듣는데 종종 멜론의 유사곡 서비스를 이용해 새로운 노래를 찾아 듣곤 한다. 
멜론에서 사용되는 노래 추천 서비스에 대하여 어떤 과정으로 진행되는지 궁금해서 알아보았다.

콘텐츠 기반 필터링(content-based filtering)에서 딥러닝 기술을 활용

오디오 원본의 웨이브 시그널을 짧은 시간별로 잘라서 각 조각마다 푸리에(Fourier) 변환을 취한 후 붙이면 해당 오디오의 2D 표현을 얻을 수 있다
인간의 귀는 컴퓨터와 달리, 주파수 간 간격이나 소리의 크기 등을 정확하게 판단하지 못한다.
저주파대역인지, 고주파대역인지에 따라 판단하는 기준이 달라지기 때문이다
이처럼 우리의 달팽이관은 인접한 주파수와 높은 주파수 대역은 잘 구분하지 못하기 때문에
이런 인간의 청각적 지각 능력에 맞춰서 로그 스케일로 스펙트로그램의 주파수 축을 줄이고 이 값들을 몇 개의 주파수 대역대로 묶으면
크기를 줄이는 동시에 가장 중요한 정보들을 보존할 수 있는 멜 스펙트로그램(mel-spectrogram)을 만들 수 있다.
멜론에서는 음원 데이터를 활용할 때 이 방식을 활용하고 있다.

오디오에서 추출한 멜 스펙트로그램이 이미지 형태의 데이터는 아니지만
최근 이미지에서 잘 동작하는 컨볼루셔널(convolutional) 모델이 오디오 데이터에서도 잘 동작한다는 연구 결과가 빈번하게 발표되고 있다.
멜론에서는 이런 컨볼루셔널 레이어를 활용한 아키텍처를 사용해 오디오의 임베딩(embedding)을 만들고
이것을 사용해서 음악의 높은 수준의 피쳐(High level feature)들을 추출하거나 임베딩 간 비슷한 정도를 활용해서 유사곡을 추천하고 있다.

데이터셋
- GTZAN Genre Collection 
  (10개의 장르에 각각 100개의 트랙, 총 30초마다 1000개의 오디오 트랙)
  (블루스, 클래식, 컨트리, 디스코, 힙합, 재즈, 메탈, 팝, 레게, 락)
- 대중적이지 않은 장르를 제외하고 몇몇의 장르들을 추가
  (댄스, 발라드, R&B/Soul, 랩/힙합, 록/메탈, 인디음악, 포크/블루스, POP, 성인가요)
- pytube 라이브러리를 이용하여 원하는 음원을 mp3 파일로 만듦.
- FMA
  (fma_small : 8개 장르에 걸쳐 8000개의 노래에서 30초씩 샘플링한 mp3 파일)

    -> 30초랑 3분이라는 길이적 차이가 있는데 이것을 어떻게 다룰것인가 ??

- 노래 장르? 



- 가능하다면 컨텐츠 기반 필터링을 사용하여 유사한 곡을 추천해주는 것 까지

장르별 100곡을 선정하여 (순위 기준?) librosa 라이브러리를 이용하여 분석한 후
특정 mp3 파일을 넣어서 장르를 분류한다.
파일은 유튜브에서 추출하는 방법을 사용


# pip install librosa
# pip install pytube
# conda install -c conda-forge ffmpeg


협업 필터링 ??
- http://millionsongdataset.com/ 


멜론 100 에 있는 장르
- 댄스, 발라드, 랩/힙합, 록/메탈, 인디음악, 포크/블루스, R&B/Soul, POP, 성인가요, 